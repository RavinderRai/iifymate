{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f959da6a-8b95-4246-b31f-e6de97aa57de",
   "metadata": {},
   "source": [
    "# Building a Vegan Likelihood Model\n",
    "\n",
    "Note: this has now changed, and we are predicting calories regardless of diet type.\n",
    "\n",
    "The goal is to build a model to either predict if a dish is vegan just from the recipe name, or create a scoring model to predict how likely or easily a recipe is or could be vegan.\n",
    "\n",
    "Or rather, we can take the cosine similarity with a user input for a recipe name and out list of recipes from out database, and then use the top score to get the list of ingredients. Then our model can predict how likely the recipe would be vegan. Could just also list out potentially ingredients that would likely show up as non-vegan in this recipe to watch out for.\n",
    "\n",
    "## EDA and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edb738a-2166-4cd7-8b6d-5631c30f035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c42503f-16cb-49ce-b3c3-2515826ad577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b720add-c477-4217-8d9d-97e5110cf0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uri', 'label', 'image', 'source', 'url', 'shareAs', 'yield',\n",
       "       'dietLabels', 'healthLabels', 'cautions', 'ingredientLines',\n",
       "       'ingredients', 'calories', 'totalWeight', 'totalTime', 'cuisineType',\n",
       "       'mealType', 'dishType', 'totalNutrients', 'totalDaily', 'digest',\n",
       "       'tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cefd959d-c5dc-4709-943f-0e53cbb038f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_col = df['ingredients'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b043d24c-6050-4f02-8fb2-3f4e64fb081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '1 pound green beans, trimmed',\n",
       "  'quantity': 1.0,\n",
       "  'measure': 'pound',\n",
       "  'food': 'green beans',\n",
       "  'weight': 453.59237,\n",
       "  'foodCategory': 'vegetables',\n",
       "  'foodId': 'food_aceucvpau4a8v6atkx5eabxyoqdn',\n",
       "  'image': 'https://www.edamam.com/food-img/891/89135f10639878a2360e6a33c9af3d91.jpg'},\n",
       " {'text': '1 tablespoon butter, (optional)',\n",
       "  'quantity': 1.0,\n",
       "  'measure': 'tablespoon',\n",
       "  'food': 'butter',\n",
       "  'weight': 14.2,\n",
       "  'foodCategory': 'Dairy',\n",
       "  'foodId': 'food_awz3iefajbk1fwahq9logahmgltj',\n",
       "  'image': 'https://www.edamam.com/food-img/713/71397239b670d88c04faa8d05035cab4.jpg'},\n",
       " {'text': 'Coarse salt and ground pepper',\n",
       "  'quantity': 0.0,\n",
       "  'measure': None,\n",
       "  'food': 'Coarse salt',\n",
       "  'weight': 2.80675422,\n",
       "  'foodCategory': 'Condiments and sauces',\n",
       "  'foodId': 'food_a1vgrj1bs8rd1majvmd9ubz8ttkg',\n",
       "  'image': 'https://www.edamam.com/food-img/694/6943ea510918c6025795e8dc6e6eaaeb.jpg'},\n",
       " {'text': 'Coarse salt and ground pepper',\n",
       "  'quantity': 0.0,\n",
       "  'measure': None,\n",
       "  'food': 'ground pepper',\n",
       "  'weight': 1.40337711,\n",
       "  'foodCategory': 'Condiments and sauces',\n",
       "  'foodId': 'food_b6ywzluaaxv02wad7s1r9ag4py89',\n",
       "  'image': 'https://www.edamam.com/food-img/c6e/c6e5c3bd8d3bc15175d9766971a4d1b2.jpg'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a78756df-82f6-4fe2-8067-f931b312e4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = dict()\n",
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44482a36-b494-4773-8084-78836899cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingredients_col[1][0]['foodCategory']\n",
    "dct[ingredients_col[1][0]['foodCategory']] = ingredients_col[1][0]['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c034e23b-b270-411b-91ab-cc0455e59d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = dict()\n",
    "for i, row in ingredients_col.items():\n",
    "    for j in range(len(row)):\n",
    "        key = row[j]['foodCategory']\n",
    "        value = row[j]['quantity']\n",
    "\n",
    "        if key in dct.keys():\n",
    "            dct[key] += value\n",
    "        else:\n",
    "            dct[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9fc5a72-a771-40f2-a02f-364f20122004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'text' in ingredients_col[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fad943c9-378f-42b0-9689-76d03095326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Eggs', 'Milk', 'Cheese', 'Dairy', 'grains', 'Condiments and sauces', 'condiments and sauces', 'Oils', 'vegetables', 'canned vegetables', 'milk', 'bread, rolls and tortillas', 'cured meats', 'fruit', 'canned grains', 'canned soup', 'bov', 'plant-based protein', 'sugars', 'quick breads and pastries', 'wines', '100% juice', 'water', 'yogurt', 'beer', 'ready-to-eat cereals', 'sugar syrups', 'Cured meats', 'crackers', 'savory snacks', 'liquors and cocktails', 'meats', 'sugar jam', 'Vegan products', 'candy', 'chocolate', None, 'canned fruit', 'non-dairy beverages', 'flavored water', 'cocktails and liquors', 'canned seafood', 'seafood', 'Poultry', 'sweetened beverages', 'pastries', 'frozen treats', 'coffee and tea', 'eggs', 'cooked grains', 'Plant-based protein', 'frozen grained based', 'mixed grains', 'sandwhiches', 'protein and nutritional powders', 'salads'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c26829e-9dd6-4c08-bd3d-2937eface087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 pound green beans, trimmed',\n",
       " '1 tablespoon butter, (optional)',\n",
       " 'Coarse salt and ground pepper']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_s = ''\n",
    "ex_s_lst = ast.literal_eval(df.iloc[0]['ingredientLines'])\n",
    "ex_s_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3a37ec-a80a-4275-9465-7c2ca754aa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 pound green beans, trimmed, 1 tablespoon butter, (optional), Coarse salt and ground pepper'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(ex_s_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc99227-97c1-4425-89ab-e835457f358f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b177d98-79f5-469b-b69a-1b7d09974a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a2f5e2-44d1-4bc5-8c18-1d45acf3b535",
   "metadata": {},
   "source": [
    "## Preprocessing for Transformer\n",
    "\n",
    "Going to try to preprocess data to take the dish/recipe name (`label` column) and the `healthLabel` as input, and output the ingredients list as a long string. We can use a transformer for this to output the recipe's ingredients in long text form. \n",
    "\n",
    "The `healthLabel` will only be a select few options though, and the user can only select 1 for now, from: ['Mediterranean', 'Vegetarian', 'Vegan', 'Red-Meat-Free', 'Paleo', 'Pescatarian']. When reducing the healthLabels column from multilabel to categorical, we need to define a priority order, and if none of these are there then the dish is balanced, so we will add that as an option. In the future, some analysis on this column should be done to improve the priority order, rather than relying on domain knowledge. Alternatively, and option to select multiple could be implemented instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9c6f09a-f93f-4da7-8221-749d8bbafb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_order = ['Vegan', 'Vegetarian', 'Pescatarian', 'Paleo', 'Red-Meat-Free', 'Mediterranean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58cce8a8-8151-4c94-aafd-227a9a869137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "1       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "2       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "3       [Sugar-Conscious, Low Potassium, Kidney-Friend...\n",
       "4       [Vegetarian, Pescatarian, Egg-Free, Peanut-Fre...\n",
       "                              ...                        \n",
       "1195    [Keto-Friendly, Pescatarian, Mediterranean, Gl...\n",
       "1196    [Pescatarian, Gluten-Free, Wheat-Free, Egg-Fre...\n",
       "1197    [Sugar-Conscious, Keto-Friendly, Pescatarian, ...\n",
       "1198    [Sugar-Conscious, Keto-Friendly, Pescatarian, ...\n",
       "1199    [Sugar-Conscious, Pescatarian, Mediterranean, ...\n",
       "Name: healthLabels, Length: 1200, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_labels = df['healthLabels'].apply(ast.literal_eval)\n",
    "health_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e874203-9b73-452c-8ca8-3486f89194a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_priority(labels):\n",
    "    for label in priority_order:\n",
    "        if label in labels:\n",
    "            return label\n",
    "    return 'Balanced'  # Handle case where no label matches priority_order, in which case the diet is balanced\n",
    "\n",
    "# Apply function to the multilabels series\n",
    "diet_type = health_labels.apply(replace_with_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fa78ee3-5e60-4ac1-bccb-18652857abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "healthLabels\n",
       "Vegetarian       400\n",
       "Vegan            279\n",
       "Pescatarian      209\n",
       "Balanced         181\n",
       "Red-Meat-Free     57\n",
       "Paleo             42\n",
       "Mediterranean     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068e884-2b21-45a4-98b9-7273114f9141",
   "metadata": {},
   "source": [
    "Now we have our dietary preference column. The recipe name is fine as is so next is the ingredients list which is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cea2701-1126-46b3-b274-b649de8b9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_name = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec883fa-1abb-43b8-bec6-e58d3b694e2e",
   "metadata": {},
   "source": [
    "We need to just join these lists of strings with commas so they be user friendly to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63f43efe-cf87-4441-a004-7bc40cf2401a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1 organic large egg, 1 teaspoon whole milk or ...\n",
       "1       375g/13oz plain flour, Pinch salt, 225g/8oz bu...\n",
       "2       1 cup asiago cheese, grated, 1 cup fontina che...\n",
       "3       4 ounces, weight Cream Cheese, Softened, 1/2 c...\n",
       "4       8 ounces elbow pasta, 1/4 cup unsalted butter,...\n",
       "                              ...                        \n",
       "1195    4 (6 ounce) tilapia fillets, salt, pepper, 1/2...\n",
       "1196    * 1 Vegetable oil cooking spray, * 4 U.S.-farm...\n",
       "1197    2 tbsp chopped red onion, 1 tbsp olive oil, 1 ...\n",
       "1198    3 tablespoons unsalted butter, 2 tablespoons e...\n",
       "1199    * 2 tilapia fillets (skinless, about 4 ounces ...\n",
       "Name: ingredientLines, Length: 1200, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_lst = df['ingredientLines'].apply(ast.literal_eval)\n",
    "ingredients_lst = ingredients_lst.apply(lambda x: ', '.join(x))\n",
    "ingredients_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83e4d7-0b6d-4067-80db-90a4beb405dc",
   "metadata": {},
   "source": [
    "Now we can make our dataframe for the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d95c300-2ddf-405b-bdc3-6202a792e31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dietType</th>\n",
       "      <th>recipeName</th>\n",
       "      <th>ingredientsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Cheese Omelette</td>\n",
       "      <td>1 organic large egg, 1 teaspoon whole milk or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Cheese straws</td>\n",
       "      <td>375g/13oz plain flour, Pinch salt, 225g/8oz bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>CHEESE GOOP</td>\n",
       "      <td>1 cup asiago cheese, grated, 1 cup fontina che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Pimento Cheese</td>\n",
       "      <td>4 ounces, weight Cream Cheese, Softened, 1/2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Five Cheese Skillet Mac and Cheese recipes</td>\n",
       "      <td>8 ounces elbow pasta, 1/4 cup unsalted butter,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dietType                                  recipeName  \\\n",
       "0  Vegetarian                             Cheese Omelette   \n",
       "1  Vegetarian                               Cheese straws   \n",
       "2  Vegetarian                                 CHEESE GOOP   \n",
       "3  Vegetarian                              Pimento Cheese   \n",
       "4  Vegetarian  Five Cheese Skillet Mac and Cheese recipes   \n",
       "\n",
       "                                     ingredientsList  \n",
       "0  1 organic large egg, 1 teaspoon whole milk or ...  \n",
       "1  375g/13oz plain flour, Pinch salt, 225g/8oz bu...  \n",
       "2  1 cup asiago cheese, grated, 1 cup fontina che...  \n",
       "3  4 ounces, weight Cream Cheese, Softened, 1/2 c...  \n",
       "4  8 ounces elbow pasta, 1/4 cup unsalted butter,...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([diet_type, recipe_name, ingredients_lst], axis = 1)\n",
    "column_names = {'healthLabels': 'dietType', 'label': 'recipeName', 'ingredientLines': 'ingredientsList'}\n",
    "df2 = df2.rename(columns=column_names)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa7957b6-80e8-49f3-a573-d895b469bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('preprocessed_recipes_context_q&a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7294644-425f-4820-81cd-66c08a96de3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipeTypeName</th>\n",
       "      <th>ingredientsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegetarian Cheese Omelette</td>\n",
       "      <td>1 organic large egg, 1 teaspoon whole milk or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegetarian Cheese straws</td>\n",
       "      <td>375g/13oz plain flour, Pinch salt, 225g/8oz bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian CHEESE GOOP</td>\n",
       "      <td>1 cup asiago cheese, grated, 1 cup fontina che...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               recipeTypeName  \\\n",
       "0  Vegetarian Cheese Omelette   \n",
       "1    Vegetarian Cheese straws   \n",
       "2      Vegetarian CHEESE GOOP   \n",
       "\n",
       "                                     ingredientsList  \n",
       "0  1 organic large egg, 1 teaspoon whole milk or ...  \n",
       "1  375g/13oz plain flour, Pinch salt, 225g/8oz bu...  \n",
       "2  1 cup asiago cheese, grated, 1 cup fontina che...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models (transformers) can't handle tabular data well so we concatenate input columns, but use df3 for context Q and A modeling\n",
    "df3 = pd.concat([df2['dietType'] + ' ' + df2['recipeName'], df2['ingredientsList']], axis = 1)\n",
    "df3 = df3.rename(columns={0: 'recipeTypeName'})\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc7fdf7-7b80-4049-8a1d-11f7e2cd6489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3.to_csv('preprocessed_example_recipes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce3170-0a84-48b4-bf52-70340f609b74",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f1311-fb55-4d19-b495-8ffd41c31b5f",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9b654-fbb2-4bd9-896e-76bba0806bb6",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Adapting this notebook: https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb#scrollTo=dEutWnhiWRAq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47991421-a8c8-40de-881b-571d8c1a6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Tensorflow:  2.13.1\n",
      "Transformers:  4.34.1\n",
      "Datasets:  2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import datasets\n",
    "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
    "import datetime\n",
    "import os\n",
    "%load_ext tensorboard\n",
    "\n",
    "tf_version = tf.__version__\n",
    "print(\"Tensorflow: \", tf_version)\n",
    "print(\"Transformers: \", transformers.__version__)\n",
    "print(\"Datasets: \", datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "410e5645-62fb-4ed7-8fa7-355abe408323",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_version_split = tf_version.split('.')\n",
    "assert int(tf_version_split[0])==2 and int(tf_version_split[-2])>=3, f\"Tensorflow version should be '2.3+,x', given {tf_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac4945ad-6085-4329-b1a3-a6dceb747024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "\n",
    "data_dir = \"./data\"\n",
    "log_dir = f\"{data_dir}/experiments/t5/logs\"\n",
    "save_path = f\"{data_dir}/experiments/t5/models\"\n",
    "cache_path_train = f\"{data_dir}/cache/t5.train\"\n",
    "cache_path_test = f\"{data_dir}/cache/t5.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "454eda6a-8256-4254-9e1f-bb16d6b8bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps:  270\n",
      "Total Validation Steps:  30\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = 1e4\n",
    "batch_size = 4\n",
    "encoder_max_len = 250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000\n",
    "ntrain = len(train_dataset)\n",
    "nvalid = len(valid_dataset)\n",
    "steps = int(np.ceil(ntrain/batch_size))\n",
    "valid_steps = int(np.ceil(nvalid/batch_size))\n",
    "print(\"Total Steps: \", steps)\n",
    "print(\"Total Validation Steps: \", valid_steps)\n",
    "\n",
    "class SnapthatT5(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name='loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training=True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training=False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f0a3c54-8934-4d22-8225-264095db88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", model_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cefcda1-0c1b-47d1-9dc2-69ae70108eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8980e1299a462c9a77964ae041a570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d423b655634256a160bfbd2af382c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70689411a91443208e504c24f11c4b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e0d6bc2-d6ac-427c-bce8-dee32ef0640a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split=\"train\")\n",
    "#valid_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d3a8cf8-7e46-45bf-9bf2-34ee9e4375b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (C:/Users/RaviB/.cache/huggingface/datasets/csv/default-5a626df6418d8a4d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split=\"train[:90%]\")\n",
    "valid_dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv', split='train[90%:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0bf69c3-f4f2-4320-b495-c06c0eae98d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipeTypeName': Value(dtype='string', id=None),\n",
       " 'ingredientsList': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "906df046-e780-4966-a59e-328588a4edc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from the dataset: \n",
      " {'recipeTypeName': 'Vegetarian Cheese Omelette', 'ingredientsList': '1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil'}\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataset))\n",
    "print(\"Example data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d178dc63-3fa7-4c39-9424-591aeaa74f73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saint Bernadette Soubirous'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(['Saint Bernadette Soubirous'])\n",
    "', '.join([i for i in list(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2c6eb70-052b-4b8c-90de-46f9740f9ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil']\n",
      "1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil </s>'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = list(['1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil'])\n",
    "print(s)\n",
    "s = ', '.join([i for i in list(s)])\n",
    "print(s)\n",
    "f\"{s} </s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d143fd0-326e-4849-b261-8e90686d79e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(example, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
    "  \n",
    "\n",
    "    recipe_type_and_name = example['recipeTypeName']\n",
    "    ingredients = example['ingredientsList']\n",
    "    \n",
    "    #context = example['context']\n",
    "    question_plus = recipe_type_and_name\n",
    "    answer = list([ingredients])\n",
    "  \n",
    "    #question_plus = f\"answer_me: {str(question)}\"\n",
    "    question_plus += \" </s>\"\n",
    "    \n",
    "    answer_plus = ', '.join([i for i in list(answer)])\n",
    "    answer_plus = f\"{answer_plus} </s>\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=encoder_max_len,\n",
    "                               pad_to_max_length=True)\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation=True, \n",
    "                               return_tensors='tf', max_length=decoder_max_len,\n",
    "                               pad_to_max_length=True)\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
    "               'labels':target_ids, 'decoder_attention_mask':target_attention}\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2f4e164-2ba9-488c-aaa4-afa1598cfa7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaviB\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds=  train_dataset.map(encode)\n",
    "valid_ds=  valid_dataset.map(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56bbb695-f90f-4734-96fc-c55449c7fa3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from the mapped dataset: \n",
      " {'recipeTypeName': 'Vegetarian Cheese Omelette', 'ingredientsList': '1 organic large egg, 1 teaspoon whole milk or water, 1 tablespoon cheddar cheese, shredded (you can use other types of cheese), 1 teaspoon butter or oil', 'input_ids': [3901, 2782, 6855, 21060, 13285, 15, 15529, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [209, 3648, 508, 6182, 6, 209, 21776, 829, 3702, 42, 387, 6, 209, 18396, 31984, 3285, 6, 3, 28559, 41, 4188, 54, 169, 119, 1308, 13, 3285, 201, 209, 21776, 4194, 42, 1043, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'decoder_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "ex = next(iter(train_ds))\n",
    "print(\"Example data from the mapped dataset: \\n\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e41c282-ecfa-4330-b9f2-34a6b4b0ac6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_tf_dataset(dataset):  \n",
    "  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "  dataset.set_format(type='tensorflow', columns=columns)\n",
    "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \n",
    "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\n",
    "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \n",
    "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\n",
    "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29822b4c-fe59-47b4-ba01-4eb43d8367d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_train_ds = to_tf_dataset(train_ds)\n",
    "tf_valid_ds = to_tf_dataset(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97a15628-30ef-47f2-82f7-2423a8cd96cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, cache_path=None, batch_size=4, \n",
    "                   buffer_size= 1000, shuffling=True):    \n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f4174e5-61e6-40aa-ae38-e17ff0ead680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size, \n",
    "                         shuffling=True, cache_path = None)\n",
    "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size, \n",
    "                         shuffling=False, cache_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb335bfa-21e6-45a1-9e35-9eb51d93a225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, warmup_steps=1e4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    m = tf.maximum(self.warmup_steps, step)\n",
    "    m = tf.cast(m, tf.float32)\n",
    "    lr = tf.math.rsqrt(m)\n",
    "    \n",
    "    return lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df237a4f-a0fb-4be2-ae2c-b64bf893428a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "schedule = CustomSchedule()\n",
    "plt.plot(schedule(tf.range(25000, dtype=tf.float32)))\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9d47ed6d-7cd4-4c7b-8510-e9c3a9440617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_profile_batch = steps+10\n",
    "stop_profile_batch = start_profile_batch + 100\n",
    "profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n",
    "\n",
    "log_path = log_dir + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,\n",
    "                                                     update_freq=20,profile_batch=profile_range)\n",
    "\n",
    "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [tensorboard_callback, model_checkpoint_callback] \n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "58d5d119-7e6b-4526-9f26-cf2e00099fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#learning_rate = CustomSchedule()\n",
    "learning_rate = 0.001  # Instead set a static learning rate\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a8842a2f-c9c9-47ec-9f6e-f109368ca778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing SnapthatT5.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model SnapthatT5 were not initialized from the PyTorch model and are newly initialized: ['total', 'count']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SnapthatT5.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c30c7f6-fa3f-4aa5-9f69-00c9a2d66359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91cdc684-2ecd-4f9a-b547-ddfbc7675338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir ./data/experiments/t5/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1662d747-44c3-4947-aabd-eefd003b1638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "     74/Unknown - 378s 5s/step - accuracy: 0.6969 - loss: 2.7471 - lr: 0.0010"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_train_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_valid_ds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:864\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\HeadphoneFinder\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_done = 0\n",
    "model.fit(tf_train_ds, epochs=2, validation_data=tf_valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f9140-f6c9-459e-97a1-cb9a62655f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df395fa6-b444-4f7d-9853-1c0964c301cc",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "\n",
    "Trying the above with pytorch since TensorFlow doesn't support windows when using GPUs anymore. Following along with https://huggingface.co/docs/transformers/tasks/question_answering to make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d16e4a7-fc74-49d4-8cbd-af5c36d46340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch can use GPU.\n",
      "Number of CUDA devices: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use GPU.\")\n",
    "    # Additional information\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))  # 0 is the GPU index\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a766c8b-d86c-44b7-aee0-5e36983e8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset(\"csv\", data_files='preprocessed_example_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8984299-6c00-49d3-b597-981e56babed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\", split=\"train[:5000]\")\n",
    "squad = squad.train_test_split(test_size=0.2)\n",
    "#train_dataset = load_dataset('squad', split='train')\n",
    "#valid_dataset = load_dataset('squad', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb41ad0f-d89d-4a59-82c2-d53916f77342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56d4c1452ccc5a1400d831dc',\n",
       " 'title': 'Beyoncé',\n",
       " 'context': 'At the 52nd Annual Grammy Awards, Beyoncé received ten nominations, including Album of the Year for I Am... Sasha Fierce, Record of the Year for \"Halo\", and Song of the Year for \"Single Ladies (Put a Ring on It)\", among others. She tied with Lauryn Hill for most Grammy nominations in a single year by a female artist. In 2010, Beyoncé was featured on Lady Gaga\\'s single \"Telephone\" and its music video. The song topped the US Pop Songs chart, becoming the sixth number-one for both Beyoncé and Gaga, tying them with Mariah Carey for most number-ones since the Nielsen Top 40 airplay chart launched in 1992. \"Telephone\" received a Grammy Award nomination for Best Pop Collaboration with Vocals.',\n",
       " 'question': 'How many nominations did Beyoncé receive at the 52nd Grammy Awards ceremony?',\n",
       " 'answers': {'text': ['ten'], 'answer_start': [51]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2899868e-f02f-432d-8112-48470bd6b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc7fc6f-03c7-44e3-848d-4e871c829b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7af0fdc-340c-441a-97a4-d4decd36c85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4575b776aefb4d83a4006ba6ed8db54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a4cc4ef9d14ca4a90e39e9cb291de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4ea2f2-0eed-41d0-b63e-16760b78f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668a1314-120c-4f2c-a3fe-d0fc77018988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc905b58-03b6-4600-b2b3-2b7d79e871e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mravinderbrai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\RaviB\\GitHub\\FlavorQuasar\\wandb\\run-20240214_175254-jkb87ip5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ravinderbrai/huggingface/runs/jkb87ip5' target=\"_blank\">alluring-sweetheart-16</a></strong> to <a href='https://wandb.ai/ravinderbrai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ravinderbrai/huggingface' target=\"_blank\">https://wandb.ai/ravinderbrai/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ravinderbrai/huggingface/runs/jkb87ip5' target=\"_blank\">https://wandb.ai/ravinderbrai/huggingface/runs/jkb87ip5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 04:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.969461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.136178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.985009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=2.756017252604167, metrics={'train_runtime': 282.8807, 'train_samples_per_second': 42.421, 'train_steps_per_second': 1.326, 'total_flos': 1175877900288000.0, 'train_loss': 2.756017252604167, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_qa_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a28e531-9f35-4864-a458-d98786ea8591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbec8d729af464d9fbcbdbcb4934173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9f1029836a4f2aa43ffba45fab9957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1846a3da0874b9da13fb7d6f59f8b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817a2b316ffc45b095a8cf1d5d89bafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1707947570.Ravi-Desktop.174520.0:   0%|          | 0.00/5.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ravinderbrai/my_awesome_qa_model/commit/b586f2247a7242a464a663060be647cb5f2e8b61', commit_message='End of training', commit_description='', oid='b586f2247a7242a464a663060be647cb5f2e8b61', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ae508e-e10b-4ce9-a1e8-cdea07f434bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'How many nominations did Beyoncé receive at the 52nd Grammy Awards ceremony?'\n",
    "context = 'At the 52nd Annual Grammy Awards, Beyoncé received ten nominations, including Album of the Year for I Am... Sasha Fierce, Record of the Year for \"Halo\", and Song of the Year for \"Single Ladies (Put a Ring on It)\", among others. She tied with Lauryn Hill for most Grammy nominations in a single year by a female artist. In 2010, Beyoncé was featured on Lady Gaga\\'s single \"Telephone\" and its music video. The song topped the US Pop Songs chart, becoming the sixth number-one for both Beyoncé and Gaga, tying them with Mariah Carey for most number-ones since the Nielsen Top 40 airplay chart launched in 1992. \"Telephone\" received a Grammy Award nomination for Best Pop Collaboration with Vocals.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ac60ae6-ebf1-4351-9528-aae05c8f8234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5852912664413452, 'start': 51, 'end': 54, 'answer': 'ten'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", model=\"my_awesome_qa_model\")\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76abf123-a5c2-4235-b424-aea9919e3874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35a0c6-bdad-42a6-aaf7-04750aa988cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15aa8499-1ad1-4af0-b679-9ec159f6666d",
   "metadata": {},
   "source": [
    "### Applying Q&A to Edamam Data\n",
    "\n",
    "Now let's adapt this to out dataset where the context is the type of diet (e.g. vegan, paleo, etc.), the question is the recipe name, and the answer will be the ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb79213-0cb4-4c71-a8cf-0d4f6a883ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! PyTorch can use GPU.\n",
      "Number of CUDA devices: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import ast\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluate import load\n",
    "\n",
    "torch.cuda.empty_cache() # clear cache for memory issues if needed\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! PyTorch can use GPU.\")\n",
    "    # Additional information\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))  # 0 is the GPU index\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use CPU.\")\n",
    "    \n",
    "df_recipes = pd.read_csv('preprocessed_recipes_context_q&a.csv')\n",
    "df_recipes_concat = pd.read_csv('preprocessed_example_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd169803-7458-4629-b30d-4e26091cfcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a69660-0918-45c1-925c-84809ee2799a",
   "metadata": {},
   "source": [
    "This is the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cedb96f6-6205-4fd3-9525-5212fd697dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13272, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_recipes = pd.read_csv('recipes.csv')\n",
    "df_raw_recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36647530-9ba8-4aca-994a-cba9f5b093eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11680, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_recipes.drop_duplicates(subset='label', keep='first', inplace=True)\n",
    "df_raw_recipes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145e48f7-c940-4d63-ab09-4e3f0a583147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dietType</th>\n",
       "      <th>recipeName</th>\n",
       "      <th>ingredientsList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Green Beans</td>\n",
       "      <td>1 pound green beans, trimmed, 1 tablespoon but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vegan</td>\n",
       "      <td>Sauteed Green Beans</td>\n",
       "      <td>1 1/2 lb green beans, stem ends trimmed, 1 tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>Caramelized Green Beans</td>\n",
       "      <td>1 stick (8 tbsp.) unsalted, cultured butter, (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vegan</td>\n",
       "      <td>Sautéed Fresh Green Beans</td>\n",
       "      <td>2 teaspoons walnut oil, 1 pound green beans, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vegan</td>\n",
       "      <td>Fancy Green Beans</td>\n",
       "      <td>1 pound green beans, trimmed, 2 teaspoons vega...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dietType                 recipeName  \\\n",
       "0  Vegetarian                Green Beans   \n",
       "1       Vegan        Sauteed Green Beans   \n",
       "2  Vegetarian    Caramelized Green Beans   \n",
       "3       Vegan  Sautéed Fresh Green Beans   \n",
       "4       Vegan          Fancy Green Beans   \n",
       "\n",
       "                                     ingredientsList  \n",
       "0  1 pound green beans, trimmed, 1 tablespoon but...  \n",
       "1  1 1/2 lb green beans, stem ends trimmed, 1 tab...  \n",
       "2  1 stick (8 tbsp.) unsalted, cultured butter, (...  \n",
       "3  2 teaspoons walnut oil, 1 pound green beans, t...  \n",
       "4  1 pound green beans, trimmed, 2 teaspoons vega...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_order = ['Vegan', 'Vegetarian', 'Pescatarian', 'Paleo', 'Red-Meat-Free', 'Mediterranean']\n",
    "health_labels = df_raw_recipes['healthLabels'].apply(ast.literal_eval)\n",
    "\n",
    "def replace_with_priority(labels):\n",
    "    for label in priority_order:\n",
    "        if label in labels:\n",
    "            return label\n",
    "    return 'Balanced'  # Handle case where no label matches priority_order, in which case the diet is balanced\n",
    "\n",
    "# Apply function to the multilabels series\n",
    "diet_type = health_labels.apply(replace_with_priority)\n",
    "\n",
    "#get the ingredients list like before\n",
    "ingredients_lst = df_raw_recipes['ingredientLines'].apply(ast.literal_eval)\n",
    "ingredients_lst = ingredients_lst.apply(lambda x: ', '.join(x))\n",
    "\n",
    "#recipe names\n",
    "recipe_name = df_raw_recipes['label']\n",
    "\n",
    "#preprocessing full dataset for LLM models\n",
    "all_recipes_df = pd.concat([diet_type, recipe_name, ingredients_lst], axis = 1)\n",
    "column_names = {'healthLabels': 'dietType', 'label': 'recipeName', 'ingredientLines': 'ingredientsList'}\n",
    "all_recipes_df = all_recipes_df.rename(columns=column_names)\n",
    "all_recipes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50be9741-9687-4d9b-871b-53917a1467af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with all three columns for context Q and A modeling\n",
    "all_recipes_df.to_csv('preprocessed_recipes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6401a90c-e336-41ff-bb47-ff054dbd8c9d",
   "metadata": {},
   "source": [
    "#### Translation Modeling\n",
    "\n",
    "Let's try to model this as a text translation problem first, following this guide: https://huggingface.co/docs/transformers/tasks/translation.\n",
    "\n",
    "This tutorial works well: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb#scrollTo=vc0BSBLIIrJQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0315d802-5592-4919-b4cf-a44040bc56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the dietType and recipeName columns to make this a seq2seq problem\n",
    "seq2seq_recipes_df = pd.concat([all_recipes_df['dietType'] + ' ' + all_recipes_df['recipeName'], all_recipes_df['ingredientsList']], axis = 1)\n",
    "seq2seq_recipes_df = seq2seq_recipes_df.rename(columns={0: 'recipeTypeName'})\n",
    "seq2seq_recipes_df.to_csv('seq2seq_preprocessed_recipes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99e8bfa2-5ef3-44b9-9806-ceaf68ccccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_concat_data = load_dataset(\"csv\", data_files=\"seq2seq_preprocessed_recipes.csv\")\n",
    "recipe_concat_data = recipe_concat_data[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b844758-c2b4-42b4-90a2-be98c90df9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, model_max_length = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2174e77c-2fd4-4b42-a0fb-e510d9f03b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipeTypeName': 'Balanced Peaches Wrapped In Prosciutto',\n",
       " 'ingredientsList': '2 peaches, 6 slices prosciutto, halved, 80 g rocket (arugula) or mixed salad leaves, ½ cup (125ml) balsamic vinegar, ¼ cup (45g) brown sugar, cracked black pepper'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_recipe_concat = recipe_concat_data['train'][0]\n",
    "example_recipe_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aead842a-97d4-4741-a412-258e7418a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    recipe_inputs = ['question-answering' + doc for doc in examples[\"recipeTypeName\"]]\n",
    "    model_inputs = tokenizer(recipe_inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    ingredients_outputs = tokenizer(text_target=examples[\"ingredientsList\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = ingredients_outputs[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d97d294-0509-4a54-afe6-15c187afb86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9950e9a1c76546a095141704436e4769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9344 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db3f26ab9fc4fed845aea86bb3b966e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2336 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_recipes = recipe_concat_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b23c5928-f982-474c-abe3-50fa2c06f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a0e0a696-7677-4335-84b4-58f272fafd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f56a080c-5341-4780-92ef-fa1c3ad2a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "29aae019-4fc1-4390-965f-321a9d31c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=7,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e767bf7-2cbd-4139-89b5-25930845a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_recipes[\"train\"],\n",
    "    eval_dataset=tokenized_recipes[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d8075e0-c3c1-4707-93e0-3962b627e2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4088' max='4088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4088/4088 31:30, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.288400</td>\n",
       "      <td>2.078649</td>\n",
       "      <td>25.171300</td>\n",
       "      <td>6.687300</td>\n",
       "      <td>20.712000</td>\n",
       "      <td>21.011700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.236800</td>\n",
       "      <td>2.036063</td>\n",
       "      <td>25.577800</td>\n",
       "      <td>6.934300</td>\n",
       "      <td>21.009800</td>\n",
       "      <td>21.317200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.178200</td>\n",
       "      <td>2.111949</td>\n",
       "      <td>25.392500</td>\n",
       "      <td>6.835300</td>\n",
       "      <td>21.049400</td>\n",
       "      <td>21.334700</td>\n",
       "      <td>18.990600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.242700</td>\n",
       "      <td>2.108967</td>\n",
       "      <td>25.472600</td>\n",
       "      <td>7.041400</td>\n",
       "      <td>21.131400</td>\n",
       "      <td>21.402700</td>\n",
       "      <td>18.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.277100</td>\n",
       "      <td>2.108965</td>\n",
       "      <td>25.484700</td>\n",
       "      <td>7.039100</td>\n",
       "      <td>21.153000</td>\n",
       "      <td>21.426900</td>\n",
       "      <td>18.989700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.277300</td>\n",
       "      <td>2.108957</td>\n",
       "      <td>25.477500</td>\n",
       "      <td>7.040900</td>\n",
       "      <td>21.131900</td>\n",
       "      <td>21.406200</td>\n",
       "      <td>18.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.277500</td>\n",
       "      <td>2.108959</td>\n",
       "      <td>25.475600</td>\n",
       "      <td>7.042200</td>\n",
       "      <td>21.134500</td>\n",
       "      <td>21.410300</td>\n",
       "      <td>18.989700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory t5-base-finetuned-xsum\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory t5-base-finetuned-xsum\\checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory t5-base-finetuned-xsum\\checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "C:\\Users\\RaviB\\anaconda3\\envs\\edamam\\Lib\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4088, training_loss=2.25644641286473, metrics={'train_runtime': 1890.9023, 'train_samples_per_second': 34.591, 'train_steps_per_second': 2.162, 'total_flos': 2266940897280000.0, 'train_loss': 2.25644641286473, 'epoch': 7.0})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "010dc06f-5c4a-452b-acb3-1e18d3af4ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1b3ff3288f4d17b08ab881cb890df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd699f0f2a24c69b86f34660cb94ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2bc0cd90484be989ed46ca86a2d264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1708258738.Ravi-Desktop.16972.0:   0%|          | 0.00/7.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ravinderbrai/t5-small-finetuned-xsum/commit/a5e77b766550ed744b9f872d30f1f72f16e04621', commit_message='End of training', commit_description='', oid='a5e77b766550ed744b9f872d30f1f72f16e04621', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b548a-d3fe-481b-a607-849531223ef2",
   "metadata": {},
   "source": [
    "#### Testing Model Output\n",
    "\n",
    "Now let's see an example of how the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d997ec4-de0c-4a4c-9e7a-60dab27f15c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 kiwi carrots, 1 medium onion and 1 carrot, 6 medium carrots, 8 oz. cauliflower florets, 2 Tbsp. milk, Salt'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_predicted_recipe(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f\"{model_name}-finetuned-xsum\")\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(f\"{model_name}-finetuned-xsum\")\n",
    "    outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "#seeing how stable the model is for the same input text\n",
    "def checking_stability(text, n=5):\n",
    "    for i in range(n):\n",
    "        print('Input Text: {}'.format(text))\n",
    "        print('Output Text:', get_predicted_recipe(text))\n",
    "        print('')\n",
    "\n",
    "get_predicted_recipe(\"Vegan Carrot Soup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72f04bbd-9593-4b93-83aa-3d4634b628c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Vegan Carrot Soup.\n",
      "Output Text: 3-4 carrots, 12 teaspoon celery seeds, 34 teaspoon salt\n",
      "\n",
      "Input Text: Vegan Carrot Soup.\n",
      "Output Text: 3 cups vegetable sour cream, 1/2 cup organic carrots, 1/3 cup butter, plus 4 cloves, 1/2 teaspoon lemon juice\n",
      "\n",
      "Input Text: Vegan Carrot Soup.\n",
      "Output Text: 4 carrots in a vegan carrot soup, if possible, made from scratch.\n",
      "\n",
      "Input Text: Vegan Carrot Soup.\n",
      "Output Text: 2 carrots (about 1 carrot), minced and diced, 2 cups vegetable broth.\n",
      "\n",
      "Input Text: Vegan Carrot Soup.\n",
      "Output Text: 2 tablespoons soy sauce, 1/3 cup carrots, 1 1/2 cup green beans, 1 egg, 1/4 cup vegetable broth, a mixture of 2 medium carrots, finely chopped, 1/4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checking_stability(\"Vegan Carrot Soup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4afa380-c3dd-411c-a4a3-b8f9495dff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Vegetarian Sphaghetti and Meatballs\n",
      "Output Text: Spritze a large handful of spinach, chopped and pitted, 4 garlic cloves, minced (optional), 3 tbsp shredded Parmesan cheese,\n",
      "\n",
      "Input Text: Vegetarian Sphaghetti and Meatballs\n",
      "Output Text: 2 pounds baby potatoes, sliced thin, 1 tablespoon oil, 1 tablespoon sphaghetti pasta, cut into 1 1/2 large slices, 1 tablespoon fresh lemon juice, 3 medium sized beef\n",
      "\n",
      "Input Text: Vegetarian Sphaghetti and Meatballs\n",
      "Output Text: 7 to 8 slices mozzarella sphaghetti, plus 1 tablespoon kosher salt, 1/4 cup sliced romaine lettuce, plus 1/4 cup chopped chives, plus 4 pieces mince\n",
      "\n",
      "Input Text: Vegetarian Sphaghetti and Meatballs\n",
      "Output Text: 1 medium zucchini, 1 tablespoon arugula, 1 teaspoon dried oregano, Salt, Pepper, Toasted Parsley, Tofu, Salt, Garlic, Ground\n",
      "\n",
      "Input Text: Vegetarian Sphaghetti and Meatballs\n",
      "Output Text: 1 egg yolk, cut into 6-inch strips, 1/2 teaspoon salt, kosher salt, pepper, 1/4 teaspoon ground pepper, 2 small tomatoes, 1 cup whole blood milk, 1/2 teaspoon extra-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checking_stability(\"Vegetarian Sphaghetti and Meatballs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2071b97-e747-4ddc-ba5f-28c28402c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summarization': {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 200, 'min_length': 30, 'no_repeat_ngram_size': 3, 'num_beams': 4, 'prefix': 'summarize: '}, 'translation_en_to_de': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to German: '}, 'translation_en_to_fr': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to French: '}, 'translation_en_to_ro': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to Romanian: '}}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "t5 = transformers.AutoModel.from_pretrained('t5-small')\n",
    "print(t5.config.task_specific_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88d920-7d40-4821-b8e7-8bd002b2469f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
