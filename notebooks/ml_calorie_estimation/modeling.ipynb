{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Prepping data for model training. For now, we will stick with a simple approach using XGBoost, and likely use old functions from the previous version of the app to do feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ravib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ravib/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ravib/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, JSON, Float\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "postgresql_password = os.environ[\"POSTGRESQL_IIFYMATE_PASSWORD\"]\n",
    "engine = create_engine(f'postgresql://iifymate:{postgresql_password}@localhost/clean_recipes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>dietLabels</th>\n",
       "      <th>healthLabels</th>\n",
       "      <th>ingredientLines</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>calories</th>\n",
       "      <th>totalWeight</th>\n",
       "      <th>totalTime</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>mealType</th>\n",
       "      <th>dishType</th>\n",
       "      <th>totalNutrients</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mom’s Swedish Potatoes recipes</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Sugar-Conscious, Vegetarian, Pescatarian, Egg...</td>\n",
       "      <td>[4 potatoes - 4, 1/2 cup Parmesan cheese grate...</td>\n",
       "      <td>[{'text': '4 potatoes - 4', 'quantity': 4.0, '...</td>\n",
       "      <td>1867.949250</td>\n",
       "      <td>1066.853125</td>\n",
       "      <td>0</td>\n",
       "      <td>[nordic]</td>\n",
       "      <td>[lunch/dinner]</td>\n",
       "      <td>[condiments and sauces]</td>\n",
       "      <td>{'Energy': {'quantity': 1867.9492500000001, 'u...</td>\n",
       "      <td>[potatoes, potato, potato dishes, swedish, swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Soft Chocolate Chip Cookies</td>\n",
       "      <td>125</td>\n",
       "      <td>[Low-Sodium]</td>\n",
       "      <td>[Low Potassium, Kidney-Friendly, Vegetarian, P...</td>\n",
       "      <td>[4.5 c. white flour, 2 tsp. baking soda, 2 c. ...</td>\n",
       "      <td>[{'text': '4.5 c. white flour', 'quantity': 4....</td>\n",
       "      <td>13300.936001</td>\n",
       "      <td>2778.900000</td>\n",
       "      <td>36</td>\n",
       "      <td>[american]</td>\n",
       "      <td>[teatime]</td>\n",
       "      <td>[biscuits and cookies]</td>\n",
       "      <td>{'Energy': {'quantity': 13300.936000549316, 'u...</td>\n",
       "      <td>[Dessert, Other, Desserts Dessert, Other Desse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                           label  serving_size    dietLabels  \\\n",
       "0   1  Mom’s Swedish Potatoes recipes             4            []   \n",
       "1   2     Soft Chocolate Chip Cookies           125  [Low-Sodium]   \n",
       "\n",
       "                                        healthLabels  \\\n",
       "0  [Sugar-Conscious, Vegetarian, Pescatarian, Egg...   \n",
       "1  [Low Potassium, Kidney-Friendly, Vegetarian, P...   \n",
       "\n",
       "                                     ingredientLines  \\\n",
       "0  [4 potatoes - 4, 1/2 cup Parmesan cheese grate...   \n",
       "1  [4.5 c. white flour, 2 tsp. baking soda, 2 c. ...   \n",
       "\n",
       "                                         ingredients      calories  \\\n",
       "0  [{'text': '4 potatoes - 4', 'quantity': 4.0, '...   1867.949250   \n",
       "1  [{'text': '4.5 c. white flour', 'quantity': 4....  13300.936001   \n",
       "\n",
       "   totalWeight  totalTime cuisineType        mealType  \\\n",
       "0  1066.853125          0    [nordic]  [lunch/dinner]   \n",
       "1  2778.900000         36  [american]       [teatime]   \n",
       "\n",
       "                  dishType                                     totalNutrients  \\\n",
       "0  [condiments and sauces]  {'Energy': {'quantity': 1867.9492500000001, 'u...   \n",
       "1   [biscuits and cookies]  {'Energy': {'quantity': 13300.936000549316, 'u...   \n",
       "\n",
       "                                                tags  \n",
       "0  [potatoes, potato, potato dishes, swedish, swe...  \n",
       "1  [Dessert, Other, Desserts Dessert, Other Desse...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql('SELECT * FROM clean_recipes', engine)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingredients Lines\n",
    "\n",
    "The main feature is the ingredients list which is a list of ingredients, so we need it to be a full string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 potatoes - 4',\n",
       " '1/2 cup Parmesan cheese grated or shredded (optional) - (more or less to taste)',\n",
       " '1/4 cup breadcrumbs - 1/4 optional, more or less to taste',\n",
       " '1/2 cup garlic butter melted - more or less to taste)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredientLines = df['ingredientLines']\n",
    "ingredientLines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comma_to_bracket(ingredient_list):\n",
    "    \"\"\"\n",
    "    Input: ingredient_list (list): a list of strings, like ingredients of a recipe.\n",
    "    Output: recipe (str): commas in individual elements from input string are removed, then they are all joined together with a comma, so commas seperate each ingredient now.\n",
    "    \"\"\"\n",
    "    processed_ingredients = []\n",
    "    \n",
    "    for ingredient in ingredient_list:\n",
    "        parts = ingredient.split(',', 1)  # Split at the first comma\n",
    "        if len(parts) > 1:  # Check if there is a comma\n",
    "            # Check if the part after the comma is already in brackets\n",
    "            if '(' not in parts[1] and ')' not in parts[1]:\n",
    "                parts[1] = f'({parts[1].strip()})'  # Put it in brackets\n",
    "        processed_ingredients.append(' '.join(parts))\n",
    "\n",
    "    # Join the processed strings with a comma and space now that we removed the commas in the individual strings\n",
    "    recipe = ', '.join(processed_ingredients)\n",
    "\n",
    "    return recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 potatoes - 4, 1/2 cup Parmesan cheese grated or shredded (optional) - (more or less to taste), 1/4 cup breadcrumbs - 1/4 optional (more or less to taste), 1/2 cup garlic butter melted - more or less to taste)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma_to_bracket(ingredientLines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredientLines = ingredientLines.apply(comma_to_bracket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_priority(labels):\n",
    "    priority_order = ['Vegan', 'Vegetarian', 'Pescatarian', 'Paleo', 'Red-Meat-Free', 'Mediterranean']\n",
    "    for label in priority_order:\n",
    "        if label in labels:\n",
    "            return label\n",
    "    return 'Balanced'  # Handle case where no label matches priority_order, in which case the diet is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the search parameter for Pescatarian is pecatarian, not pescatarian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthLabels = df['healthLabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegetarian\n",
      "Vegetarian\n",
      "Vegetarian\n",
      "Vegetarian\n",
      "Vegan\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(replace_with_priority(healthLabels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthLabels = healthLabels.apply(replace_with_priority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_macros(nutrients_row: dict):\n",
    "    macros_dct = {}\n",
    "\n",
    "    macros_dct['Fat'] = nutrients_row['Fat']['quantity']\n",
    "    macros_dct['Protein'] = nutrients_row['Protein']['quantity']\n",
    "    macros_dct['Carbohydrates (net)'] = nutrients_row['Carbohydrates (net)']['quantity']\n",
    "    \n",
    "    return macros_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'quantity': 112.83458124999999, 'unit': 'g'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_nutrients = df['totalNutrients'][0]\n",
    "print(type(sample_nutrients))\n",
    "sample_nutrients['Fat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fat': 112.83458124999999,\n",
       " 'Protein': 48.66716875,\n",
       " 'Carbohydrates (net)': 151.89527062499997}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_macros(sample_nutrients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Variables\n",
    "\n",
    "Here we want our features that will be the input for the ML model to be the recipe name, ingredents, and health labels. They will all be concatenated together to have it all as just one string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Vegetarian\n",
       "1     Vegetarian\n",
       "2     Vegetarian\n",
       "3     Vegetarian\n",
       "4          Vegan\n",
       "         ...    \n",
       "95    Vegetarian\n",
       "96    Vegetarian\n",
       "97      Balanced\n",
       "98    Vegetarian\n",
       "99    Vegetarian\n",
       "Name: healthLabels, Length: 100, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vegetarian Mom’s Swedish Potatoes recipes 4 potatoes - 4, 1/2 cup Parmesan cheese grated or shredded (optional) - (more or less to taste), 1/4 cup breadcrumbs - 1/4 optional (more or less to taste), 1/2 cup garlic butter melted - more or less to taste)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = healthLabels + \" \" + df['label'] + \" \" + ingredientLines\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Vegetarian Mom’s Swedish Potatoes recipes 4 po...\n",
       "1     Vegetarian Soft Chocolate Chip Cookies 4.5 c. ...\n",
       "2     Vegetarian Zucchini Bread with Lemon Honey But...\n",
       "3     Vegetarian Crispy Zucchini Sticks with Spicy M...\n",
       "4     Vegan Bourbon BBQ Sauce, Perfect for Summer Gr...\n",
       "                            ...                        \n",
       "95    Vegetarian Semolina Halva with Currants 125g b...\n",
       "96    Vegetarian Almond Joy Muffins * 2 cups flour, ...\n",
       "97    Balanced Puff Pastry Pasty 2 sheets puff pastr...\n",
       "98    Vegetarian Yogurt Bowl With Citrus And Rosemar...\n",
       "99    Vegetarian Chive Buttered Carrots Recipe 4 2-1...\n",
       "Name: fullRecipeInput, Length: 100, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.rename('fullRecipeInput')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(review):\n",
    "    english_stop_words = stopwords.words('english')\n",
    "\n",
    "    #get the words in the review as a list\n",
    "    review_words = review.split()\n",
    "    \n",
    "    #make a new list with the same words but only if they are not a stop word\n",
    "    removed_stop_words_list = [word for word in review_words if word not in english_stop_words]\n",
    "    \n",
    "    removed_stop_words = ' '.join(removed_stop_words_list)\n",
    "    \n",
    "    return removed_stop_words\n",
    "\n",
    "def lemmatizing_reviews(review):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    #get review text as a list of words\n",
    "    review_list = review.split()\n",
    "    \n",
    "    #lemmatize the words\n",
    "    lemmatized_list = [lemmatizer.lemmatize(word) for word in review_list]\n",
    "    \n",
    "    #make it into a string again\n",
    "    lemmatized_review = ' '.join(lemmatized_list)\n",
    "    \n",
    "    return lemmatized_review\n",
    "\n",
    "def get_tfidf_splits(X, y, test_size=0.25, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "\n",
    "    tfidf_fitted = tfidf.fit(X_train.str.join(' '))\n",
    "\n",
    "    tfidf_X_train_labels = tfidf_fitted.transform(X_train.str.join(' '))\n",
    "    tfidf_X_test_labels = tfidf_fitted.transform(X_test.str.join(' '))\n",
    "    tfidf_train_df = pd.DataFrame(tfidf_X_train_labels.toarray(), columns=tfidf.get_feature_names_out())\n",
    "    tfidf_test_df = pd.DataFrame(tfidf_X_test_labels.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "    return tfidf_train_df, tfidf_test_df, y_train, y_test, tfidf_fitted\n",
    "\n",
    "def SVD_reduction(X_train, X_test, n_components=1000):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    svd_fitted = svd.fit(X_train)\n",
    "    X_train_reduced, X_test_reduced = svd.transform(X_train), svd.transform(X_test)\n",
    "\n",
    "    #getting column names just to convert to dataframe\n",
    "    column_names = [f\"component_{i+1}\" for i in range(X_train_reduced.shape[1])]\n",
    "    X_train_reduced_df = pd.DataFrame(X_train_reduced, columns=column_names, index=X_train.index)\n",
    "    X_test_reduced_df = pd.DataFrame(X_test_reduced, columns=column_names, index=X_test.index)\n",
    "\n",
    "    return X_train_reduced_df, X_test_reduced_df, svd_fitted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(remove_stop_words)\n",
    "X = X.apply(lemmatizing_reviews)\n",
    "X = X.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = df['totalNutrients']\n",
    "\n",
    "y = pd.DataFrame(list(nutrients.apply(lambda row: get_macros(row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fat</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Carbohydrates (net)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.834581</td>\n",
       "      <td>48.667169</td>\n",
       "      <td>151.895271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>756.216820</td>\n",
       "      <td>163.182420</td>\n",
       "      <td>1446.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>333.545213</td>\n",
       "      <td>48.968544</td>\n",
       "      <td>410.634439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.649808</td>\n",
       "      <td>59.859046</td>\n",
       "      <td>141.431198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.784801</td>\n",
       "      <td>18.865246</td>\n",
       "      <td>212.039270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fat     Protein  Carbohydrates (net)\n",
       "0  112.834581   48.667169           151.895271\n",
       "1  756.216820  163.182420          1446.628000\n",
       "2  333.545213   48.968544           410.634439\n",
       "3   93.649808   59.859046           141.431198\n",
       "4   43.784801   18.865246           212.039270"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, tfidf_fitted = get_tfidf_splits(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, svd_fitted = SVD_reduction(X_train, X_test, n_components=500)\n",
    "\n",
    "y_train, y_test = np.log1p(y_train), np.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_2</th>\n",
       "      <th>component_3</th>\n",
       "      <th>component_4</th>\n",
       "      <th>component_5</th>\n",
       "      <th>component_6</th>\n",
       "      <th>component_7</th>\n",
       "      <th>component_8</th>\n",
       "      <th>component_9</th>\n",
       "      <th>component_10</th>\n",
       "      <th>...</th>\n",
       "      <th>component_66</th>\n",
       "      <th>component_67</th>\n",
       "      <th>component_68</th>\n",
       "      <th>component_69</th>\n",
       "      <th>component_70</th>\n",
       "      <th>component_71</th>\n",
       "      <th>component_72</th>\n",
       "      <th>component_73</th>\n",
       "      <th>component_74</th>\n",
       "      <th>component_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226480</td>\n",
       "      <td>-0.140697</td>\n",
       "      <td>0.113005</td>\n",
       "      <td>0.114324</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.141355</td>\n",
       "      <td>0.324709</td>\n",
       "      <td>-0.107398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.040666</td>\n",
       "      <td>0.089013</td>\n",
       "      <td>-0.012655</td>\n",
       "      <td>-0.062293</td>\n",
       "      <td>0.045922</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.052368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.340595</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.251554</td>\n",
       "      <td>-0.145342</td>\n",
       "      <td>-0.310863</td>\n",
       "      <td>-0.088318</td>\n",
       "      <td>0.034694</td>\n",
       "      <td>0.082445</td>\n",
       "      <td>0.045782</td>\n",
       "      <td>0.105308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036608</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.097754</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>-0.047521</td>\n",
       "      <td>0.039682</td>\n",
       "      <td>0.021428</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.016525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.498234</td>\n",
       "      <td>0.392715</td>\n",
       "      <td>-0.018806</td>\n",
       "      <td>-0.052989</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.065180</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>-0.104278</td>\n",
       "      <td>-0.124184</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071309</td>\n",
       "      <td>-0.089109</td>\n",
       "      <td>-0.027824</td>\n",
       "      <td>0.228905</td>\n",
       "      <td>-0.182257</td>\n",
       "      <td>0.185085</td>\n",
       "      <td>0.061021</td>\n",
       "      <td>-0.021868</td>\n",
       "      <td>-0.047261</td>\n",
       "      <td>0.005234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258781</td>\n",
       "      <td>-0.276750</td>\n",
       "      <td>0.016255</td>\n",
       "      <td>0.324764</td>\n",
       "      <td>-0.137843</td>\n",
       "      <td>-0.001772</td>\n",
       "      <td>0.053871</td>\n",
       "      <td>-0.319701</td>\n",
       "      <td>-0.117181</td>\n",
       "      <td>-0.138065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111904</td>\n",
       "      <td>-0.085179</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>-0.052594</td>\n",
       "      <td>0.016307</td>\n",
       "      <td>0.045310</td>\n",
       "      <td>-0.044218</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>-0.018177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294368</td>\n",
       "      <td>-0.253503</td>\n",
       "      <td>-0.161766</td>\n",
       "      <td>-0.125963</td>\n",
       "      <td>-0.006361</td>\n",
       "      <td>0.168606</td>\n",
       "      <td>-0.060922</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>-0.028583</td>\n",
       "      <td>-0.296809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141183</td>\n",
       "      <td>0.070582</td>\n",
       "      <td>-0.139994</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>-0.060555</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>-0.019441</td>\n",
       "      <td>-0.055849</td>\n",
       "      <td>-0.009477</td>\n",
       "      <td>-0.022512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   component_1  component_2  component_3  component_4  component_5  \\\n",
       "0     0.226480    -0.140697     0.113005     0.114324     0.044962   \n",
       "1     0.340595    -0.000927    -0.251554    -0.145342    -0.310863   \n",
       "2     0.498234     0.392715    -0.018806    -0.052989     0.105894   \n",
       "3     0.258781    -0.276750     0.016255     0.324764    -0.137843   \n",
       "4     0.294368    -0.253503    -0.161766    -0.125963    -0.006361   \n",
       "\n",
       "   component_6  component_7  component_8  component_9  component_10  ...  \\\n",
       "0     0.075223    -0.000027    -0.141355     0.324709     -0.107398  ...   \n",
       "1    -0.088318     0.034694     0.082445     0.045782      0.105308  ...   \n",
       "2     0.065180     0.020539    -0.104278    -0.124184      0.012171  ...   \n",
       "3    -0.001772     0.053871    -0.319701    -0.117181     -0.138065  ...   \n",
       "4     0.168606    -0.060922     0.011016    -0.028583     -0.296809  ...   \n",
       "\n",
       "   component_66  component_67  component_68  component_69  component_70  \\\n",
       "0      0.042900      0.022293     -0.010431      0.040666      0.089013   \n",
       "1     -0.036608      0.007042     -0.000085     -0.097754      0.001296   \n",
       "2     -0.071309     -0.089109     -0.027824      0.228905     -0.182257   \n",
       "3     -0.111904     -0.085179      0.035480     -0.052594      0.016307   \n",
       "4     -0.141183      0.070582     -0.139994      0.010694     -0.060555   \n",
       "\n",
       "   component_71  component_72  component_73  component_74  component_75  \n",
       "0     -0.012655     -0.062293      0.045922      0.002983      0.052368  \n",
       "1     -0.047521      0.039682      0.021428      0.059801      0.016525  \n",
       "2      0.185085      0.061021     -0.021868     -0.047261      0.005234  \n",
       "3      0.045310     -0.044218      0.007663      0.000672     -0.018177  \n",
       "4      0.003720     -0.019441     -0.055849     -0.009477     -0.022512  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fat</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Carbohydrates (net)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.832761</td>\n",
       "      <td>5.550206</td>\n",
       "      <td>5.759905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.935185</td>\n",
       "      <td>4.001894</td>\n",
       "      <td>5.984178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.397143</td>\n",
       "      <td>3.992935</td>\n",
       "      <td>6.204824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.205701</td>\n",
       "      <td>5.085594</td>\n",
       "      <td>6.362206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.983302</td>\n",
       "      <td>2.361232</td>\n",
       "      <td>3.293822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fat   Protein  Carbohydrates (net)\n",
       "15  5.832761  5.550206             5.759905\n",
       "40  4.935185  4.001894             5.984178\n",
       "96  5.397143  3.992935             6.204824\n",
       "9   5.205701  5.085594             6.362206\n",
       "72  1.983302  2.361232             3.293822"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "With the features from above, we can now train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fat_args = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': None}\n",
    "carbs_args = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': None}\n",
    "protein_args = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_macro_model(X_train, X_test, y_train, y_test, macro, args):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost regressor model for predicting a specific macronutrient (carbs, fat, or protein) \n",
    "    using the recipe data from the Edamam API. Returns the trained model along with evaluation metrics.\n",
    "\n",
    "    Parameters:\n",
    "    X_train : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "        Training data.\n",
    "    X_test : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "        Test data.\n",
    "    y_train : DataFrame, shape (n_samples, n_targets)\n",
    "        Target values for training data.\n",
    "    y_test : DataFrame, shape (n_samples, n_targets)\n",
    "        Target values for test data.\n",
    "    macro : str\n",
    "        Name of the target macronutrient variable (column) in y_train and y_test.\n",
    "    args : dict\n",
    "        Dictionary containing arguments to be passed to the XGBRegressor constructor.\n",
    "\n",
    "    Returns:\n",
    "    xgb_model : XGBRegressor object\n",
    "        Trained XGBoost regressor model.\n",
    "    r2 : float\n",
    "        R-squared score on the test data.\n",
    "    mse : float\n",
    "        Mean squared error on the test data.\n",
    "    \"\"\"\n",
    "    xgb = XGBRegressor(**args)\n",
    "    xgb.fit(X_train, y_train[macro])\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    r2 = r2_score(y_test[macro], y_pred)\n",
    "    mse = mean_squared_error(y_test[macro], y_pred)\n",
    "\n",
    "    return xgb, r2, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fat_xgb, fat_r2, fat_mse = get_xgb_macro_model(X_train, X_test, y_train, y_test, 'Fat', fat_args)\n",
    "\n",
    "carbs_xgb, carbs_r2, carbs_mse = get_xgb_macro_model(X_train, X_test, y_train, y_test, 'Carbohydrates (net)', carbs_args)\n",
    "\n",
    "protein_xgb, protein_r2, protein_mse = get_xgb_macro_model(X_train, X_test, y_train, y_test, 'Protein', protein_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fat_xgb.predict(X_test)\n",
    "r2 = r2_score(y_test['Fat'], y_pred)\n",
    "mse = mean_squared_error(y_test['Fat'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "print(fat_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/ravib/projects/iifymate/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/feast/feature_view.py:48: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity '__dummy'.\n",
      "  DUMMY_ENTITY = Entity(\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/mlflow/gateway/config.py:62: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"togetherai_api_key\", pre=True)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/mlflow/gateway/config.py:370: PydanticDeprecatedSince20: Pydantic V1 style `@root_validator` validators are deprecated. You should migrate to Pydantic V2 style `@model_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @root_validator(skip_on_failure=True)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ml_features/ml_calorie_estimation/mlruns'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from feast import FeatureStore\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import mlflow.sklearn\n",
    "from xgboost import XGBRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "\n",
    "from ml_features.ml_calorie_estimation.src.training.multi_train import train_all_macro_models\n",
    "from ml_features.ml_calorie_estimation.src.training.data_validation import clean_training_testing_data\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ML_PROJECT_ROOT = Path(\"ml_features/ml_calorie_estimation\")\n",
    "MLFLOW_TRACKING_URI = os.path.join(ML_PROJECT_ROOT, \"mlruns\")\n",
    "MLFLOW_TRACKING_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data():\n",
    "    # Initialize feature store\n",
    "    \"\"\"\n",
    "    Loads training and testing data from parquet files saved by the feature engineering pipeline\n",
    "    and returns them as separate Pandas DataFrames.\n",
    "    \n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): The Pandas DataFrame containing the features for training.\n",
    "        X_test (pd.DataFrame): The Pandas DataFrame containing the features for testing.\n",
    "        y_train (pd.DataFrame): The Pandas DataFrame containing the targets for training.\n",
    "        y_test (pd.DataFrame): The Pandas DataFrame containing the targets for testing.\n",
    "    \"\"\"\n",
    "    store = FeatureStore(\"ml_features/ml_calorie_estimation/feature_store/feature_repo\")\n",
    "    \n",
    "    # Load features and targets from parquet directly\n",
    "    # Since we saved everything in one file, it's simpler to read directly\n",
    "    feature_df = pd.read_parquet(\"ml_features/ml_calorie_estimation/feature_store/feature_repo/data/recipe_features.parquet\")\n",
    "    test_df = pd.read_parquet(\"ml_features/ml_calorie_estimation/feature_store/feature_repo/data/test_features.parquet\")\n",
    "    \n",
    "    # Separate features and targets\n",
    "    feature_cols = [col for col in feature_df.columns if col.startswith('component_')]\n",
    "    target_cols = [col for col in feature_df.columns if col.startswith('target_')]\n",
    "    \n",
    "    X_train = feature_df[feature_cols]\n",
    "    y_train = feature_df[target_cols]\n",
    "    \n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[target_cols]    \n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1511, 500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "macros = ['target_Fat', 'target_Carbohydrates_net', 'target_Protein']\n",
    "env = \"local\"\n",
    "cv_folds = 3 if env == \"local\" else 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Target target_Fat: 388 NaN, 0 inf\n",
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Target target_Carbohydrates_net: 388 NaN, 0 inf\n",
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Target target_Protein: 388 NaN, 0 inf\n",
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Removed 388 rows (25.68%) containing NaN or inf values\n",
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Target target_Fat: 366 NaN, 0 inf\n",
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Target target_Carbohydrates_net: 366 NaN, 0 inf\n",
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Target target_Protein: 366 NaN, 0 inf\n",
      "WARNING:ml_features.ml_calorie_estimation.src.training.data_validation:Removed 366 rows (72.62%) containing NaN or inf values\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = clean_training_testing_data(X_train, y_train, macros)\n",
    "X_test, y_test = clean_training_testing_data(X_test, y_test, macros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1123, 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [3],\n",
    "}\n",
    "\n",
    "model = XGBRegressor()\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=cv_folds,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    #n_jobs=2 if env == \"local\" else -1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.904509\n",
       "1       3.539324\n",
       "3       6.516199\n",
       "4       5.774548\n",
       "5       5.732992\n",
       "          ...   \n",
       "1506    3.793802\n",
       "1507    2.070305\n",
       "1508    5.682403\n",
       "1509    4.362724\n",
       "1510    5.134735\n",
       "Name: target_Fat, Length: 1123, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[macros[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...in=None,\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [3]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...in=None,\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01], &#x27;max_depth&#x27;: [3]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...in=None,\n",
       "                                    max_cat_threshold=None,\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01], 'max_depth': [3]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train[macros[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_macro_model(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    macro: str,\n",
    "    param_grid: dict,\n",
    "    cv_folds: int = 3\n",
    ") -> dict:\n",
    "    model = XGBRegressor()\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        #n_jobs=2 if env == \"local\" else -1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train,y_train[macro])\n",
    "    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search_macro_model(X_train, y_train, macros[0], param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:440: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:312: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:314: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(dtype) and enable_categorical:\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:345: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype)\n",
      "/home/ravib/projects/iifymate/.iifymate/lib/python3.12/site-packages/xgboost/data.py:336: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "xgb_macro_0 = XGBRegressor(**best_params)\n",
    "\n",
    "xgb_macro_0.fit(X_train, y_train[macros[0]])\n",
    "\n",
    "y_pred = xgb_macro_0.predict(X_test)\n",
    "r2 = r2_score(y_test[macros[0]], y_pred)\n",
    "mse = mean_squared_error(y_test[macros[0]], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.646989461187976"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_macro_model(\n",
    "    X_train: pd.DataFrame, \n",
    "    y_train: pd.DataFrame, \n",
    "    macro: str, \n",
    "    model_params: dict,\n",
    "):\n",
    "    \"\"\"Grid search trains with a validation set, so we retrain on the whole training data using the best params\"\"\"\n",
    "    model = XGBRegressor(**model_params)\n",
    "    model.fit(X_train, y_train[macro])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".iifymate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
